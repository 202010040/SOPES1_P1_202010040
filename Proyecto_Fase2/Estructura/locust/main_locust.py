import json
import time
from datetime import datetime
from locust import HttpUser, task, between
from locust.env import Environment
import requests
import random
from http.server import HTTPServer, BaseHTTPRequestHandler
import threading

# Configuraciones globales - ACTUALIZADAS CON IPs CORRECTAS
BALANCED_API_ENDPOINT = "http://34.121.110.88/api/metrics"  # nginx-lb-service que balancea autom√°ticamente
METRICS_SOURCE_ENDPOINT = "http://34.27.149.243:3001"
API_LECTURA_ENDPOINT = "http://34.55.86.146:8080"  # Para WebSocket si es necesario

# Cola para los datos recibidos del endpoint de m√©tricas
received_data_queue = []
phase1_complete = False
direct_mode = False  # Modo directo sin guardar en JSON
target_records = 2000  # Objetivo de registros

class MetricsFetcherUser(HttpUser):
    """FASE 1: Usuario para obtener datos del endpoint de m√©tricas hasta completar 2000 registros"""
    wait_time = between(1, 2)  # Entre 1-2 segundos seg√∫n requisitos
    host = METRICS_SOURCE_ENDPOINT
    
    def on_start(self):
        print("üéØ FASE 1: Obteniendo m√©tricas desde endpoint iniciado")
    
    @task
    def fetch_metrics_data(self):
        """Obtiene datos del endpoint de m√©tricas"""
        global target_records
        
        # Si ya alcanzamos el objetivo, no hacer m√°s peticiones
        if len(received_data_queue) >= target_records:
            print(f"üéØ Objetivo alcanzado: {len(received_data_queue)}/{target_records} registros")
            return
            
        try:
            # Hacer petici√≥n GET al endpoint de m√©tricas
            response = self.client.get("/api/metrics", timeout=10)
            
            if response.status_code == 200:
                try:
                    data = response.json()
                    
                    # Validar que tenga todos los campos requeridos
                    required_fields = [
                        'total_ram', 'ram_libre', 'uso_ram', 'porcentaje_ram',
                        'porcentaje_cpu_uso', 'porcentaje_cpu_libre',
                        'procesos_corriendo', 'total_procesos', 'procesos_durmiendo',
                        'procesos_zombie', 'procesos_parados', 'hora'
                    ]
                    
                    missing_fields = [field for field in required_fields if field not in data]
                    if missing_fields:
                        print(f"‚ö†Ô∏è Datos incompletos. Faltan: {missing_fields}")
                        return
                    
                    # Agregar timestamp e ID √∫nico si no existen
                    if 'timestamp' not in data:
                        data['timestamp'] = datetime.now().isoformat()
                    if 'id' not in data:
                        data['id'] = f"{int(time.time() * 1000)}_{random.randint(1000, 9999)}"
                    
                    # En modo directo, enviar inmediatamente a la API balanceada
                    if direct_mode:
                        self.send_data_to_balanced_api(data)
                    else:
                        # Agregar a la cola solo si no hemos alcanzado el objetivo
                        if len(received_data_queue) < target_records:
                            received_data_queue.append(data)
                    
                    current_count = len(received_data_queue)
                    print(f"üìä Datos obtenidos - {'Enviado directo' if direct_mode else f'Cola: {current_count}/{target_records}'} - RAM: {data.get('porcentaje_ram', 'N/A')}% - CPU: {data.get('porcentaje_cpu_uso', 'N/A')}%")
                    
                except json.JSONDecodeError:
                    print(f"‚ùå Error decodificando JSON de la respuesta")
                    
            elif response.status_code != 0:
                print(f"‚ö†Ô∏è Endpoint respuesta {response.status_code}")
                
        except requests.exceptions.Timeout:
            print(f"‚è±Ô∏è Timeout en petici√≥n al endpoint")
        except Exception as e:
            print(f"‚ùå Error obteniendo m√©tricas: {e}")
    
    def send_data_to_balanced_api(self, data):
        """Env√≠a datos directamente a la API balanceada (nginx hace el balanceo autom√°ticamente)"""
        try:
            data_copy = data.copy()
            data_copy['api'] = 'Balanced'  # Marcador para identificar que va a la API balanceada
            
            response = requests.post(
                BALANCED_API_ENDPOINT,
                json=data_copy,
                headers={"Content-Type": "application/json"},
                timeout=5
            )
            
            if response.status_code in [200, 201]:
                print(f"‚úÖ Directo‚ÜíBalanceada - RAM: {data.get('porcentaje_ram', 'N/A')}% - CPU: {data.get('porcentaje_cpu_uso', 'N/A')}%")
            else:
                print(f"‚ö†Ô∏è Directo‚ÜíBalanceada error {response.status_code}")
                    
        except Exception as e:
            print(f"‚ùå Error enviando datos a API balanceada: {e}")

class BalancedTrafficUser(HttpUser):
    """FASE 2: Usuario para enviar datos a la API balanceada (nginx hace el balanceo autom√°ticamente)"""
    wait_time = between(1, 4)  # Entre 1-4 segundos seg√∫n requisitos
    host = "http://34.121.110.88"  # nginx-lb-service
    
    def on_start(self):
        print("‚öñÔ∏è FASE 2: Enviando a API balanceada - nginx distribuye autom√°ticamente")
    
    def get_next_data_item(self):
        """Obtiene el siguiente elemento de datos de la cola"""
        if received_data_queue:
            return received_data_queue.pop(0)
        return None
    
    @task
    def send_to_balanced_api(self):
        """Env√≠a objeto individual a la API balanceada"""
        data_item = self.get_next_data_item()
        
        if data_item:
            # Agregar identificador para la API balanceada
            data_item['api'] = 'Balanced'
            data_item['load_balancer'] = 'nginx'
            
            try:
                response = self.client.post(
                    "/api/metrics",
                    json=data_item,
                    headers={"Content-Type": "application/json"}
                )
                
                if response.status_code in [200, 201]:
                    print(f"‚úÖ Balanceada - RAM: {data_item.get('porcentaje_ram', 'N/A')}% - CPU: {data_item.get('porcentaje_cpu_uso', 'N/A')}%")
                else:
                    print(f"‚ö†Ô∏è Balanceada error {response.status_code}")
                    # Devolver a cola sin los campos adicionales
                    if 'api' in data_item:
                        del data_item['api']
                    if 'load_balancer' in data_item:
                        del data_item['load_balancer']
                    received_data_queue.insert(0, data_item)
                    
            except Exception as e:
                print(f"‚ùå API Balanceada error: {e}")
                if 'api' in data_item:
                    del data_item['api']
                if 'load_balancer' in data_item:
                    del data_item['load_balancer']
                received_data_queue.insert(0, data_item)

def generate_dummy_data(num_records=2000):
    """Genera datos dummy simulando m√©tricas del sistema"""
    dummy_data = []
    
    print(f"üé≤ Generando {num_records} registros dummy...")
    
    for i in range(num_records):
        # Generar datos realistas
        total_ram = random.randint(8000, 32000)  # MB
        ram_usado = random.randint(int(total_ram * 0.3), int(total_ram * 0.9))
        ram_libre = total_ram - ram_usado
        porcentaje_ram = round((ram_usado / total_ram) * 100, 2)
        
        cpu_uso = round(random.uniform(10, 95), 2)
        cpu_libre = round(100 - cpu_uso, 2)
        
        total_procesos = random.randint(200, 500)
        procesos_corriendo = random.randint(1, 10)
        procesos_durmiendo = total_procesos - procesos_corriendo - random.randint(0, 5)
        procesos_zombie = random.randint(0, 3)
        procesos_parados = total_procesos - procesos_corriendo - procesos_durmiendo - procesos_zombie
        
        # Crear timestamp con variaci√≥n
        base_time = datetime.now()
        timestamp_variation = random.randint(-3600, 0)  # Hasta 1 hora atr√°s
        record_time = base_time.timestamp() + timestamp_variation
        
        dummy_record = {
            "id": f"dummy_{int(time.time() * 1000)}_{random.randint(1000, 9999)}",
            "timestamp": datetime.fromtimestamp(record_time).isoformat(),
            "total_ram": total_ram,
            "ram_libre": ram_libre,
            "uso_ram": ram_usado,
            "porcentaje_ram": porcentaje_ram,
            "porcentaje_cpu_uso": cpu_uso,
            "porcentaje_cpu_libre": cpu_libre,
            "procesos_corriendo": procesos_corriendo,
            "total_procesos": total_procesos,
            "procesos_durmiendo": procesos_durmiendo,
            "procesos_zombie": procesos_zombie,
            "procesos_parados": procesos_parados,
            "hora": datetime.fromtimestamp(record_time).strftime("%H:%M:%S"),
            "dummy": True  # Marcador para identificar datos dummy
        }
        
        dummy_data.append(dummy_record)
        
        # Mostrar progreso cada 500 registros
        if (i + 1) % 500 == 0:
            print(f"üìä Generados {i + 1}/{num_records} registros dummy...")
    
    return dummy_data

def save_dummy_json(num_records=2000):
    """Genera y guarda un archivo JSON con datos dummy"""
    print("üé≤ GENERANDO DATOS DUMMY")
    
    try:
        # Generar datos dummy
        dummy_data = generate_dummy_data(num_records)
        
        # Crear archivo JSON
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"dummy_metrics_data_{timestamp}.json"
        
        json_data = {
            "metadata": {
                "total_records": len(dummy_data),
                "generated_at": datetime.now().isoformat(),
                "type": "dummy_data",
                "description": "Datos de m√©tricas simuladas para testing",
                "records_requested": num_records,
                "load_balancer": "nginx",
                "api_endpoint": BALANCED_API_ENDPOINT
            },
            "metrics": dummy_data
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(json_data, f, indent=2, ensure_ascii=False)
        
        print(f"‚úÖ Archivo dummy generado: {filename}")
        print(f"üìä Registros creados: {len(dummy_data)}")
        
        # Cargar datos en memoria para distribuci√≥n inmediata si se desea
        load_choice = input("\n¬øCargar datos dummy en memoria para distribuci√≥n? (y/n): ").strip().lower()
        if load_choice == 'y':
            received_data_queue.extend(dummy_data)
            print(f"üì• {len(dummy_data)} registros dummy cargados en memoria")
            return filename, True
        
        return filename, False
        
    except Exception as e:
        print(f"‚ùå Error generando datos dummy: {e}")
        return None, False

def save_generated_json():
    """Guarda el JSON con los datos generados en la Fase 1"""
    if received_data_queue:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"metrics_data_{timestamp}.json"
        
        # Crear una copia de los datos para el JSON
        json_data = {
            "metadata": {
                "total_records": len(received_data_queue),
                "generated_at": datetime.now().isoformat(),
                "phase": "Fase 1 - Obtenci√≥n de datos del endpoint",
                "source_endpoint": METRICS_SOURCE_ENDPOINT,
                "target_records": target_records,
                "users": 300,
                "load_balancer": "nginx",
                "balanced_api_endpoint": BALANCED_API_ENDPOINT
            },
            "metrics": received_data_queue.copy()
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(json_data, f, indent=2, ensure_ascii=False)
        
        print(f"üíæ JSON generado: {filename}")
        print(f"üìä Registros guardados: {len(received_data_queue)}")
        return filename
    else:
        print("‚ùå No hay datos para generar JSON")
        return None

def run_phase1_metrics_collection():
    """FASE 1: Obtiene datos del endpoint hasta completar 2000 registros"""
    global phase1_complete, target_records
    
    print("=== FASE 1: OBTENCI√ìN DE M√âTRICAS INICIADA ===")
    print(f"üéØ Objetivo: {target_records} registros")
    print(f"üì° Endpoint: {METRICS_SOURCE_ENDPOINT}")
    print("üë• 300 usuarios, 1-2 seg entre peticiones, +1 usuario/seg")
    
    # Configurar Locust para Fase 1
    env = Environment(user_classes=[MetricsFetcherUser])
    env.create_local_runner()
    
    users = 300
    spawn_rate = 1  # 1 usuario por segundo seg√∫n requisitos
    
    print(f"üöÄ Iniciando {users} usuarios obteniendo m√©tricas")
    env.runner.start(user_count=users, spawn_rate=spawn_rate)
    
    start_time = time.time()
    
    print(f"‚è±Ô∏è Ejecutando hasta completar {target_records} registros...")
    
    while len(received_data_queue) < target_records:
        elapsed = int(time.time() - start_time)
        queue_size = len(received_data_queue)
        progress = (queue_size / target_records) * 100
        
        print(f"üìà Tiempo: {elapsed}s - Progreso: {queue_size}/{target_records} ({progress:.1f}%) - Faltantes: {target_records - queue_size}")
        
        # Verificar si han pasado muchos minutos sin progreso
        if elapsed > 600 and queue_size < 100:  # 10 minutos sin muchos registros
            print("‚ö†Ô∏è ADVERTENCIA: Poco progreso en 10 minutos. Verifica la conectividad del endpoint.")
        
        time.sleep(10)  # Reporte cada 10 segundos
    
    env.runner.stop()
    phase1_complete = True
    
    final_count = len(received_data_queue)
    elapsed_total = int(time.time() - start_time)
    print(f"‚úÖ FASE 1 COMPLETADA en {elapsed_total}s - Registros obtenidos: {final_count}")
    
    # GENERAR EL ARCHIVO JSON REQUERIDO
    json_file = save_generated_json()
    if json_file:
        print(f"üìÅ Archivo JSON creado: {json_file}")
    
    return final_count

def run_phase2_balanced_distribution():
    """FASE 2: Distribuye los datos a la API balanceada con 150 usuarios"""
    print("\n=== FASE 2: DISTRIBUCI√ìN A API BALANCEADA INICIADA ===")
    print("‚öñÔ∏è 150 usuarios, 1-4 seg entre peticiones, +1 usuario/seg")
    print(f"üìä API Balanceada: {BALANCED_API_ENDPOINT}")
    print("üîÑ nginx-lb-service distribuye autom√°ticamente entre NodeJS y Python")
    
    # Configurar Locust para Fase 2
    env = Environment(user_classes=[BalancedTrafficUser])
    env.create_local_runner()
    
    users = 150  # Seg√∫n requisitos
    spawn_rate = 1  # 1 usuario por segundo
    
    print(f"üöÄ Iniciando {users} usuarios enviando a API balanceada")
    env.runner.start(user_count=users, spawn_rate=spawn_rate)
    
    print("üéØ Enviando datos a:")
    print("   - nginx-lb-service (balanceador)")
    print("   - Distribuir√° autom√°ticamente entre:")
    print("     * api-monitoreo (NodeJS - puerto 4001)")
    print("     * api-monitoreo-python (Python - puerto 5001)")
    print("\nPresiona Ctrl+C para parar...")
    
    try:
        while True:
            time.sleep(10)
            queue_size = len(received_data_queue)
            if queue_size > 0:
                print(f"üìà Cola restante: {queue_size} elementos")
            else:
                print("‚è≥ Cola vac√≠a, esperando m√°s datos o presiona Ctrl+C...")
                
    except KeyboardInterrupt:
        print("\nüõë Parando distribuci√≥n...")
    
    env.runner.stop()
    print("‚úÖ FASE 2 COMPLETADA")

def run_direct_balanced_mode():
    """Modo directo: obtiene datos del endpoint y los env√≠a inmediatamente a la API balanceada"""
    global direct_mode
    direct_mode = True
    
    print("=== MODO DIRECTO BALANCEADO INICIADO ===")
    print(f"üéØ Endpoint {METRICS_SOURCE_ENDPOINT} ‚Üí API Balanceada directamente")
    print(f"‚öñÔ∏è nginx-lb-service: {BALANCED_API_ENDPOINT}")
    print("‚ö° Sin almacenamiento en JSON, sin cola intermedia")
    print("üîÑ nginx distribuye autom√°ticamente entre NodeJS y Python")
    
    # Configurar Locust para modo directo
    env = Environment(user_classes=[MetricsFetcherUser])
    env.create_local_runner()
    
    users = 50  # Menos usuarios para modo directo
    spawn_rate = 1
    
    print(f"üöÄ Iniciando {users} usuarios en modo directo balanceado")
    env.runner.start(user_count=users, spawn_rate=spawn_rate)
    
    print("üîÑ Esperando datos del endpoint...")
    print("üìä Los datos se enviar√°n autom√°ticamente a la API balanceada")
    print("‚öñÔ∏è nginx-lb-service distribuir√° entre:")
    print("   - api-monitoreo (NodeJS - puerto 4001)")
    print("   - api-monitoreo-python (Python - puerto 5001)")
    print("\nPresiona Ctrl+C para parar...")
    
    try:
        while True:
            time.sleep(5)
            print("‚è≥ Modo directo balanceado activo, obteniendo y enviando datos...")
            
    except KeyboardInterrupt:
        print("\nüõë Parando modo directo balanceado...")
    finally:
        env.runner.stop()
        direct_mode = False
        print("‚úÖ MODO DIRECTO BALANCEADO COMPLETADO")

def load_json_data(filename):
    """Carga datos desde un archivo JSON generado previamente"""
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # Si el JSON tiene metadata, extraer solo las m√©tricas
        if 'metrics' in data:
            metrics = data['metrics']
        else:
            metrics = data
        
        # Cargar los datos en la cola
        received_data_queue.extend(metrics)
        
        print(f"üìÅ JSON cargado: {filename}")
        print(f"üìä Registros cargados: {len(metrics)}")
        return len(metrics)
        
    except FileNotFoundError:
        print(f"‚ùå Archivo no encontrado: {filename}")
        return 0
    except Exception as e:
        print(f"‚ùå Error cargando JSON: {e}")
        return 0

def save_remaining_data():
    """Guarda datos restantes en archivo JSON"""
    if received_data_queue:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"remaining_data_{timestamp}.json"
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(received_data_queue, f, indent=2, ensure_ascii=False)
        
        print(f"üíæ {len(received_data_queue)} registros guardados en {filename}")
        return filename
    else:
        print("‚úÖ No hay datos restantes para guardar")
        return None

def run_complete_balanced_test():
    """Ejecuta el test completo: Fase 1 + Fase 2 con API balanceada"""
    try:        
        print("üåü INICIANDO TEST COMPLETO DE CARGA CON API BALANCEADA")
        print("üìã Requisitos del proyecto:")
        print(f"   - Fase 1: 300 usuarios, hasta {target_records} registros")
        print("   - Fase 2: 150 usuarios, env√≠o a API balanceada")
        print(f"   - Endpoint de m√©tricas: {METRICS_SOURCE_ENDPOINT}")
        print(f"   - API Balanceada: {BALANCED_API_ENDPOINT}")
        print("   - nginx-lb-service distribuye autom√°ticamente entre NodeJS y Python\n")
        
        # FASE 1: Obtenci√≥n de datos
        records_generated = run_phase1_metrics_collection()
        
        if records_generated < 100:
            print("‚ùå ERROR: Muy pocos registros obtenidos. Verifica:")
            print(f"   1. Endpoint {METRICS_SOURCE_ENDPOINT} est√° accesible")
            print("   2. El endpoint devuelve datos en formato JSON v√°lido")
            print("   3. Los datos contienen todos los campos requeridos")
            return
        
        print(f"\n‚è∏Ô∏è Pausa de 5 segundos entre fases...")
        time.sleep(5)
        
        # FASE 2: Distribuci√≥n a API balanceada
        run_phase2_balanced_distribution()
        
        print("\nüéâ TEST COMPLETO CON API BALANCEADA FINALIZADO")
        
    except KeyboardInterrupt:
        print("\nüîÑ Test interrumpido por usuario...")
    except Exception as e:
        print(f"‚ùå Error en test completo: {e}")
    finally:
        save_remaining_data()
        print("‚úÖ Proceso terminado")

if __name__ == "__main__":
    print("üöÄ LOCUST - PROYECTO FASE 2 - SO1 (API BALANCEADA)")
    print("=" * 50)
    
    # Verificar configuraci√≥n
    print("üîß Verificando configuraci√≥n:")
    print(f"   - Endpoint m√©tricas: {METRICS_SOURCE_ENDPOINT}")
    print(f"   - API Balanceada: {BALANCED_API_ENDPOINT}")
    print(f"   - API Lectura: {API_LECTURA_ENDPOINT}")
    print(f"   - Objetivo registros: {target_records}")
    print("   - Balanceador: nginx-lb-service (autom√°tico)")
    
    # Opciones de ejecuci√≥n actualizadas
    print("\nüìã OPCIONES DE EJECUCI√ìN:")
    print("1. Ejecutar test completo balanceado (Fase 1 + Fase 2)")
    print("2. Solo Fase 1 (obtener datos y generar JSON)")
    print("3. Solo Fase 2 balanceada (cargar JSON existente)")
    print("4. Continuar con datos en memoria")
    print("5. üé≤ Generar JSON con datos dummy")
    print("6. ‚ö° Modo directo balanceado (endpoint ‚Üí API balanceada)")
    
    try:
        choice = input("\nSelecciona una opci√≥n (1-6): ").strip()
        
        if choice == "1":
            run_complete_balanced_test()
        elif choice == "2":
            # Solo Fase 1
            run_phase1_metrics_collection()
        elif choice == "3":
            # Solo Fase 2 con JSON existente
            json_file = input("Ingresa el nombre del archivo JSON: ").strip()
            if json_file and load_json_data(json_file) > 0:
                run_phase2_balanced_distribution()
            else:
                print("‚ùå No se pudo cargar el archivo JSON")
        elif choice == "4":
            # Continuar con datos en memoria
            if len(received_data_queue) > 0:
                print(f"üìä Datos en memoria: {len(received_data_queue)}")
                run_phase2_balanced_distribution()
            else:
                print("‚ùå No hay datos en memoria")
        elif choice == "5":
            # Generar datos dummy
            try:
                num_records = input(f"N√∫mero de registros dummy (default {target_records}): ").strip()
                num_records = int(num_records) if num_records else target_records
                filename, loaded = save_dummy_json(num_records)
                
                if filename and loaded:
                    # Si se cargaron en memoria, ofrecer distribuci√≥n
                    distribute = input("¬øIniciar distribuci√≥n de datos dummy a API balanceada? (y/n): ").strip().lower()
                    if distribute == 'y':
                        run_phase2_balanced_distribution()
            except ValueError:
                print("‚ùå N√∫mero inv√°lido")
        elif choice == "6":
            # Modo directo balanceado
            run_direct_balanced_mode()
        else:
            print("‚ùå Opci√≥n inv√°lida")
            
    except KeyboardInterrupt:
        print("\nüîÑ Interrumpido por usuario...")
        save_remaining_data()
    except Exception as e:
        print(f"‚ùå Error cr√≠tico: {e}")
        save_remaining_data()